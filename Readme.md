# ğŸ¢ AdventureWorks Data Warehouse - OLAP Implementation

> **Demo Project**: Implementasi Data Warehouse dengan Star Schema menggunakan ClickHouse, DBT, dan Medallion Architecture untuk presentasi pembelajaran OLAP vs OLTP.

> **Dataset Required**: Download the AdventureWorks CSV files from [here](https://www.kaggle.com/datasets/ukveteran/adventure-works) before proceeding.

---

## ğŸ¯ Overview

Project ini mendemonstrasikan:
- âœ… **OLTP vs OLAP** - Perbedaan struktur dan use case
- âœ… **ELT Process** - Extract, Load, Transform menggunakan DBT
- âœ… **Medallion Architecture** - Bronze â†’ Silver layer
- âœ… **Star Schema** - Dimensional modeling (Fact & Dimension tables)
- âœ… **OLAP Operations** - Drill-down, Roll-up, Slice, Dice
- âœ… **Modern Data Stack** - ClickHouse + DBT

### Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Database** | ClickHouse | OLAP database engine |
| **Transformation** | DBT (Data Build Tool) | ELT transformations |
| **Orchestration** | Docker Compose | Container management |
| **Language** | Python 3.8+ | Data loading scripts |

---

## Architecture

### Medallion Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CSV Files (Raw Data)                      â”‚
â”‚  AdventureWorks_Products.csv, Sales_2015.csv, etc.          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ Python Script (EL)
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               BRONZE LAYER (Raw/OLTP-like)                   â”‚
â”‚  Tables: Products, Customers, Sales_2015, Sales_2016, etc.  â”‚
â”‚  Purpose: Staging area, minimal transformation               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ DBT (Transform)
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SILVER LAYER (Star Schema/OLAP)                 â”‚
â”‚  â€¢ Fact: Fact_Sales                                          â”‚
â”‚  â€¢ Dimensions: Dim_Date, Dim_Product, Dim_Customer,          â”‚
â”‚                Dim_Territory                                 â”‚
â”‚  Purpose: Analytics-ready, optimized for queries             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Star Schema Design

```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Dim_Date   â”‚
              â”‚  DateKey PK â”‚
              â”‚  Year       â”‚
              â”‚  Quarter    â”‚
              â”‚  Month      â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dim_Product  â”‚    â”‚    â”‚ Dim_Customer â”‚
â”‚ ProductKey PKâ”‚    â”‚    â”‚ CustomerKey  â”‚
â”‚ Name         â”‚    â”‚    â”‚ FullName     â”‚
â”‚ Category     â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤ City         â”‚
â”‚ SubCategory  â”‚    â”‚    â”‚ Demographics â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ Fact_Sales â”‚
              â”‚ SalesKey PKâ”‚
              â”‚ DateKey FK â”‚
              â”‚ ProductKey â”‚
              â”‚ CustomerKeyâ”‚
              â”‚ TerrKey FK â”‚
              â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
              â”‚ Quantity   â”‚
              â”‚ SalesAmt   â”‚
              â”‚ TaxAmt     â”‚
              â”‚ Freight    â”‚
              â”‚ ProfitAmt  â”‚
              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Dim_Territory  â”‚
              â”‚ TerritoryKey PKâ”‚
              â”‚ Region         â”‚
              â”‚ Country        â”‚
              â”‚ Continent      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
.

â”‚
â”œâ”€â”€ dbt/                                # DBT project folder
â”‚   â”œâ”€â”€ adventureworks/
â”‚   â”‚   â”œâ”€â”€ dbt_project.yml            # DBT project config
â”‚   â”‚   â”œâ”€â”€ profiles.yml               # Database connection
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ bronze/                # (Optional) Bronze models
â”‚   â”‚       â””â”€â”€ silver/                # Star schema models
â”‚   â”‚           â”œâ”€â”€ sources.yml        # Source table definitions
â”‚   â”‚           â”œâ”€â”€ schema.yml         # Model documentation
â”‚   â”‚           â”œâ”€â”€ dim_date.sql       # Date dimension
â”‚   â”‚           â”œâ”€â”€ dim_product.sql    # Product dimension
â”‚   â”‚           â”œâ”€â”€ dim_customer.sql   # Customer dimension
â”‚   â”‚           â”œâ”€â”€ dim_territory.sql  # Territory dimension
â”‚   â”‚           â””â”€â”€ fact_sales.sql     # Sales fact table
â”‚   â”‚
â”‚   â””â”€â”€ logs/                          # DBT logs
â”‚
â”œâ”€â”€ docker-compose.yml                 # ClickHouse container setup
â”œâ”€â”€ csv_to_clickhouse.py              # Import CSV to ClickHouse (Bronze)
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ profiles.yml                       # DBT profiles (alternative location)
â””â”€â”€ README.md                          # This file
```

---

## ğŸ”§ Prerequisites

### Required Software

- **Docker & Docker Compose** (v20.10+)
- **Python** (3.8+)
- **pip** (Python package manager)

### Check Installation

```bash
# Check Docker
docker --version
docker-compose --version

# Check Python
python --version
pip --version
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Start ClickHouse Database

```bash
# Start ClickHouse container
docker-compose up -d

# Verify it's running
docker ps


```

Wait ~20 seconds for ClickHouse to fully initialize.

### 2ï¸âƒ£ Load Bronze Layer (Raw Data)

```bash
# Install Python dependencies
pip install -r requirements.txt

# Place CSV files in csv_files/ folder
# Then run import script
python csv_to_clickhouse.py
```

Expected output:
```
ğŸš€ ClickHouse CSV Importer for AdventureWorks
============================================================
âœ… ClickHouse is ready!
âœ… Database 'adventureworks' created/verified

ğŸ“‚ Found 9 CSV file(s)

============================================================
ğŸ“ Processing: AdventureWorks_Products.csv
ğŸ“Š Target table: Products
   âœ… Imported 606 rows successfully

ğŸ“Š IMPORT SUMMARY
============================================================
âœ… Successfully imported: 9 table(s)
```

### 3ï¸âƒ£ Transform to Silver Layer (Star Schema)

```bash
# Navigate to DBT project
cd dbt/adventureworks

# Install DBT
pip install dbt-core dbt-clickhouse

# Test connection
dbt debug

# Run transformations
dbt run

# Run tests
dbt test
```

Expected output:
```
Running with dbt=1.7.0
Found 5 models, 12 tests, 0 snapshots

Completed successfully

Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
```


---

## ğŸ“š Detailed Setup

### Step 1: Clone/Setup Project

```bash
# Create project directory
mkdir adventureworks_dwh
cd adventureworks_dwh

# Create necessary folders
mkdir csv_files
mkdir dbt
```

### Step 2: Configure ClickHouse

**File: `docker-compose.yml`**

```yaml
version: '3.8'

services:
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse-server
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native client
    environment:
      - CLICKHOUSE_DB=adventureworks
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=password123
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./csv_files:/csv_files:ro

volumes:
  clickhouse_data:
```

Start container:
```bash
docker-compose up -d
```

### Step 3: Load Bronze Layer

**File: `requirements.txt`**
```
clickhouse-connect==0.7.16
pandas==2.1.4
numpy==1.26.2
```

Install dependencies:
```bash
pip install -r requirements.txt
```

Run import script:
```bash
python csv_to_clickhouse.py
```

### Step 4: Setup DBT

**Navigate to DBT folder:**
```bash
cd dbt/adventureworks
```

**File: `profiles.yml`** (in `~/.dbt/` or project root)
```yaml
adventureworks:
  target: dev
  outputs:
    dev:
      type: clickhouse
      schema: adventureworks_silver
      host: localhost
      port: 8123
      user: default
      password: password123
      database: adventureworks
```

**Test connection:**
```bash
dbt debug
```

### Step 5: Run DBT Models

```bash
# Run all models
dbt run

# Run specific model
dbt run --select dim_product

# Run with full refresh
dbt run --full-refresh

# Run tests
dbt test

# Generate documentation
dbt docs generate
dbt docs serve  # Open browser at http://localhost:8080
```

---

## ğŸ”„ Data Pipeline

### Pipeline Flow

```
1. EXTRACT & LOAD (Python Script)
   â”œâ”€â”€ Read CSV files from csv_files/
   â”œâ”€â”€ Auto-detect encoding (UTF-8, Latin-1, etc.)
   â”œâ”€â”€ Skip problematic lines
   â”œâ”€â”€ Create tables in ClickHouse
   â””â”€â”€ Load data to Bronze layer

2. TRANSFORM (DBT)
   â”œâ”€â”€ Read from Bronze tables (sources.yml)
   â”œâ”€â”€ Apply business logic (SQL models)
   â”œâ”€â”€ Create Star Schema tables
   â”‚   â”œâ”€â”€ Dim_Date (date dimension)
   â”‚   â”œâ”€â”€ Dim_Product (product hierarchy)
   â”‚   â”œâ”€â”€ Dim_Customer (customer attributes)
   â”‚   â”œâ”€â”€ Dim_Territory (geography)
   â”‚   â””â”€â”€ Fact_Sales (transactional metrics)
   â””â”€â”€ Write to Silver layer

3. VALIDATE (DBT Tests)
   â”œâ”€â”€ Unique key constraints
   â”œâ”€â”€ Not null checks
   â”œâ”€â”€ Referential integrity
   â””â”€â”€ Custom business rules
```

### Re-running Pipeline

```bash
# Full refresh (drop & recreate all tables)
cd dbt/adventureworks
dbt run --full-refresh

# Incremental update (if configured)
dbt run

# Run specific models
dbt run --select dim_product+  # dim_product and downstream models
dbt run --select +fact_sales   # fact_sales and upstream models
```

---

<!-- ## ğŸ“Š OLAP Queries Examples

### 1. ROLL-UP (Aggregate to higher level)

```sql
-- From Monthly â†’ Quarterly
SELECT 
    d.Year,
    d.Quarter,
    SUM(f.SalesAmount) as total_sales,
    SUM(f.ProfitAmount) as total_profit
FROM adventureworks_silver.fact_sales f
JOIN adventureworks_silver.dim_date d ON f.DateKey = d.DateKey
GROUP BY d.Year, d.Quarter
ORDER BY d.Year, d.Quarter;
```

### 2. DRILL-DOWN (Breakdown to lower level)

```sql
-- From Category â†’ Products
SELECT 
    p.ProductCategoryName,
    p.ProductName,
    SUM(f.OrderQuantity) as units_sold,
    SUM(f.SalesAmount) as revenue
FROM adventureworks_silver.fact_sales f
JOIN adventureworks_silver.dim_product p ON f.ProductKey = p.ProductKey
WHERE p.ProductCategoryName = 'Bikes'
GROUP BY p.ProductCategoryName, p.ProductName
ORDER BY revenue DESC
LIMIT 10;
```

### 3. SLICE (Filter one dimension)

```sql
-- Sales for Year 2016 only
SELECT 
    p.ProductCategoryName,
    t.Country,
    SUM(f.SalesAmount) as total_sales
FROM adventureworks_silver.fact_sales f
JOIN adventureworks_silver.dim_date d ON f.DateKey = d.DateKey
JOIN adventureworks_silver.dim_product p ON f.ProductKey = p.ProductKey
JOIN adventureworks_silver.dim_territory t ON f.TerritoryKey = t.TerritoryKey
WHERE d.Year = 2016  -- SLICE on time dimension
GROUP BY p.ProductCategoryName, t.Country
ORDER BY total_sales DESC;
```

### 4. DICE (Filter multiple dimensions)

```sql
-- Bikes in USA, Q1 2016
SELECT 
    d.MonthName,
    c.City,
    SUM(f.SalesAmount) as sales,
    SUM(f.ProfitAmount) as profit
FROM adventureworks_silver.fact_sales f
JOIN adventureworks_silver.dim_date d ON f.DateKey = d.DateKey
JOIN adventureworks_silver.dim_product p ON f.ProductKey = p.ProductKey
JOIN adventureworks_silver.dim_customer c ON f.CustomerKey = c.CustomerKey
JOIN adventureworks_silver.dim_territory t ON f.TerritoryKey = t.TerritoryKey
WHERE 
    d.Year = 2016 
    AND d.Quarter = 1
    AND p.ProductCategoryName = 'Bikes'
    AND t.Country = 'United States'
GROUP BY d.MonthName, c.City
ORDER BY sales DESC;
```

### 5. PIVOT (Rotate data)

```sql
-- Sales by Product Category and Year
SELECT 
    p.ProductCategoryName,
    SUM(CASE WHEN d.Year = 2015 THEN f.SalesAmount ELSE 0 END) as Sales_2015,
    SUM(CASE WHEN d.Year = 2016 THEN f.SalesAmount ELSE 0 END) as Sales_2016,
    SUM(CASE WHEN d.Year = 2017 THEN f.SalesAmount ELSE 0 END) as Sales_2017
FROM adventureworks_silver.fact_sales f
JOIN adventureworks_silver.dim_date d ON f.DateKey = d.DateKey
JOIN adventureworks_silver.dim_product p ON f.ProductKey = p.ProductKey
GROUP BY p.ProductCategoryName
ORDER BY p.ProductCategoryName;
``` -->


## ğŸ“– References

- [ClickHouse Documentation](https://clickhouse.com/docs)
- [DBT Documentation](https://docs.getdbt.com/)
- [AdventureWorks Dataset](https://github.com/Microsoft/sql-server-samples)
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)

---


## ğŸ¯ Next Steps

After completing this demo:
1. âœ… Add more complex transformations (SCD Type 2)
2. âœ… Implement incremental loads
3. âœ… Add data quality checks
4. âœ… Create BI dashboard (Metabase/Superset)
5. âœ… Add Gold layer for business metrics

---

**Happy Learning! ğŸš€**